{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import tqdm  # For progress bar during processing\n",
    "from osgeo import gdal\n",
    "import matplotlib.dates as mdates\n",
    "from maxflow import Graph\n",
    "from scipy.stats import zscore  # Import zscore for blunder detection\n",
    "\n",
    "# Function to get geotransform information from an image\n",
    "def get_geotransform(image_path):\n",
    "    dataset = gdal.Open(str(image_path))\n",
    "    if dataset is not None:\n",
    "        geotransform = dataset.GetGeoTransform()\n",
    "        dataset = None  # Close the dataset by assigning it to None\n",
    "        return geotransform\n",
    "    return None\n",
    "\n",
    "# Convert meshgrid pixel coordinates to geographic coordinates (lon, lat)\n",
    "def pixel_to_latlon(geotransform, meshgrid_x, meshgrid_y):\n",
    "    lon = geotransform[0] + meshgrid_x * geotransform[1] + meshgrid_y * geotransform[2]\n",
    "    lat = geotransform[3] + meshgrid_x * geotransform[4] + meshgrid_y * geotransform[5]\n",
    "    return lon, lat\n",
    "\n",
    "# Extract date information from the filename\n",
    "def extract_date_from_filename(filename):\n",
    "    date_str = filename.split('.')[1][1:]\n",
    "    year = int(date_str[:4])\n",
    "    day_of_year = int(date_str[4:])\n",
    "    base_date = datetime(year, 1, 1)\n",
    "    date_object = base_date + timedelta(days=day_of_year - 1)\n",
    "    return year, date_object.month, date_object.day\n",
    "\n",
    "# Function to create and apply masks for cloud removal\n",
    "def apply_cloud_masks(image_files, overall_percentage, water_percentage_threshold, cloud_mask_threshold, output_folder):\n",
    "    # Create a folder to store modified images\n",
    "    modified_folder = output_folder / \"Modified_Images_WaterMask\"\n",
    "    modified_folder.mkdir(exist_ok=True)  # Create Modified_Images_WaterMask folder if it doesn't exist\n",
    "\n",
    "    skipped_images = []\n",
    "\n",
    "    # Loop through each image file\n",
    "    for image_file in image_files:\n",
    "        img_ds = gdal.Open(str(image_file))\n",
    "        img_array = img_ds.ReadAsArray()\n",
    "\n",
    "        # Check if image dimensions match the overall percentage array\n",
    "        if img_array.shape != overall_percentage.shape:\n",
    "            print(f\"Image {image_file} has different dimensions. Skipping.\")\n",
    "            skipped_images.append(image_file)\n",
    "            continue\n",
    "\n",
    "        # Create a mask based on overall percentage\n",
    "        cloud_mask = np.where(overall_percentage <= cloud_mask_threshold, 1, 0)\n",
    "\n",
    "        # Apply the mask to the image array\n",
    "        masked_array = np.where(cloud_mask[np.newaxis, :, :] == 1, 0, img_array)\n",
    "\n",
    "        # Additional mask based on water occurrence percentage threshold\n",
    "        water_mask = np.where(overall_percentage >= water_percentage_threshold, 1, 0)\n",
    "        masked_array = np.where(water_mask[np.newaxis, :, :] == 1, 1, masked_array)\n",
    "\n",
    "        # Check and adjust the dimensionality of the masked_array\n",
    "        if len(masked_array.shape) == 3:\n",
    "            # If masked_array has 3 dimensions, collapse the first dimension\n",
    "            masked_array = masked_array.squeeze()\n",
    "\n",
    "        # Save the modified image\n",
    "        modified_path = str(modified_folder / image_file.name)  # Convert Path object to string\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        modified_ds = driver.Create(modified_path, img_ds.RasterXSize, img_ds.RasterYSize, 1, gdal.GDT_Int16)\n",
    "        modified_ds.SetGeoTransform(img_ds.GetGeoTransform())\n",
    "        modified_ds.SetProjection(img_ds.GetProjection())\n",
    "        modified_ds.GetRasterBand(1).WriteArray(masked_array)\n",
    "        modified_ds = None  # Close the dataset\n",
    "\n",
    "    print(\"Cloud removal process completed.\")\n",
    "    return skipped_images\n",
    "\n",
    "# Function to get a valid folder path\n",
    "def get_valid_folder_path():\n",
    "    while True:\n",
    "        folder_name = input(\"Enter the lake name: \")\n",
    "        folder_path = Path(\"/Users/masoud/Documents/Thesis/Data\") / folder_name\n",
    "\n",
    "        if folder_path.is_dir():\n",
    "            return folder_path\n",
    "        else:\n",
    "            print(f\"Folder '{folder_name}' not found. Please enter a valid folder name.\")\n",
    "\n",
    "# Function to process images in a folder\n",
    "def process_image_folder(folder_path):\n",
    "    # Get a list of image files in the folder\n",
    "    image_files = [f for f in folder_path.iterdir() if f.suffix.lower() in {\".tif\", \".tiff\"}]\n",
    "\n",
    "    # Check if there are any TIFF files in the folder\n",
    "    if not image_files:\n",
    "        print(f\"No TIFF files found in folder {folder_path.name}.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Sort image files based on date\n",
    "    image_files.sort(key=lambda x: extract_date_from_filename(x.name))\n",
    "    \n",
    "    # Open the first image to get dimensions and geotransform information\n",
    "    first_image_ds = gdal.Open(str(image_files[0]))\n",
    "    width = first_image_ds.RasterXSize\n",
    "    height = first_image_ds.RasterYSize\n",
    "    num_images = len(image_files)\n",
    "    \n",
    "    # Generate meshgrid for the first image using latitudes and longitudes\n",
    "    meshgrid_x, meshgrid_y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    meshgrid_lon, meshgrid_lat = pixel_to_latlon(get_geotransform(image_files[0]), meshgrid_x, meshgrid_y)\n",
    "\n",
    "    monthly_matrices = {month: [] for month in range(1, 13)}\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    progress_bar = tqdm.tqdm(total=num_images, desc='Processing Images', unit='image', position=0)\n",
    "    \n",
    "    # Loop through each image in the folder\n",
    "    for image_file in image_files:\n",
    "        img_ds = gdal.Open(str(image_file))\n",
    "        img_array = img_ds.ReadAsArray()\n",
    "\n",
    "        # Check if image dimensions match the first image\n",
    "        if img_array.shape[:2] != (height, width):\n",
    "            print(f\"Image {image_file} in folder {folder_path.name} has different dimensions. Skipping.\")\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "\n",
    "        # Convert certain pixel values to standardized values (0, 1, 2)\n",
    "        img_array[img_array == 32769] = 1 # Water\n",
    "        img_array[(img_array == 0) | (img_array == 32768)] = 0 # Land\n",
    "        img_array[(img_array == 4) | (img_array == 32772)] = 2 # Cloud\n",
    "\n",
    "        # Check the percentage of clouds (pixel value 2)\n",
    "        cloud_percentage = (np.sum(img_array == 2) / img_array.size) * 100\n",
    "\n",
    "        # Skip images with high cloud coverage\n",
    "        if (cloud_percentage >= 85) or (np.all(img_array == 2)):\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "        else:\n",
    "            year, month, _ = extract_date_from_filename(image_file.name)\n",
    "            monthly_matrices[month].append(img_array)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Close the tqdm progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Convert lists of arrays to arrays\n",
    "    for month in monthly_matrices:\n",
    "        monthly_matrices[month] = np.array(monthly_matrices[month])\n",
    "\n",
    "    return monthly_matrices, meshgrid_lon, meshgrid_lat\n",
    "\n",
    "# Calculate monthly percentage of water occurrence\n",
    "def calculate_monthly_percentage(monthly_matrices):\n",
    "    monthly_percentages = []\n",
    "\n",
    "    # Create a tqdm progress bar for monthly calculation\n",
    "    progress_bar = tqdm.tqdm(total=12, desc='Calculating Monthly Percentages', unit='month', position=0)\n",
    "\n",
    "    # Loop through each month\n",
    "    for month in range(1, 13):\n",
    "        # Extract relevant data for the month\n",
    "        monthly_matrix = monthly_matrices[month]\n",
    "        if len(monthly_matrix) == 0:\n",
    "            monthly_percentages.append((calendar.month_name[month], None))\n",
    "            progress_bar.update(1)\n",
    "            continue\n",
    "        # Calculate monthly percentage\n",
    "        monthly_percentage = ((np.sum(monthly_matrix == 1, axis=0)) / (np.sum((monthly_matrix == 1) | (monthly_matrix == 0), axis=0))) * 100\n",
    "        # Store result for the month\n",
    "        monthly_percentages.append((calendar.month_name[month], monthly_percentage))\n",
    "\n",
    "        # Increment the progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    return monthly_percentages\n",
    "\n",
    "# Visualize monthly water occurrence\n",
    "def visualize_monthly_percentage(monthly_percentages, output_folder, meshgrid_lon, meshgrid_lat):\n",
    "    height, width = meshgrid_lon.shape\n",
    "\n",
    "    # Calculate longitudes and latitudes using vectorized pixel_to_latlon function for the first image\n",
    "    lon, lat = meshgrid_lon, meshgrid_lat\n",
    "\n",
    "    for month_name, pixel_percentage in monthly_percentages:\n",
    "        if pixel_percentage is None:\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(pixel_percentage, extent=(lon.min(), lon.max(), lat.min(), lat.max()), cmap='Blues', vmin=0, vmax=100)\n",
    "        plt.title(f\"Water Occurrence - {month_name}\")\n",
    "        plt.colorbar(label='Water Coverage Frequency')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.grid(True, linestyle='--', linewidth=0.5, color='black', alpha=0.5)\n",
    "\n",
    "        # Save the plot as PNG in the Output folder\n",
    "        output_path_png = output_folder / f\"water_occurrence_{month_name}.png\"\n",
    "        plt.savefig(output_path_png)\n",
    "        plt.close()\n",
    "\n",
    "def calculate_overall_percentage(monthly_matrices):\n",
    "    # Initialize arrays to accumulate sums and counts\n",
    "    overall_sum = None\n",
    "    overall_count = None\n",
    "\n",
    "    num_months = len(monthly_matrices)\n",
    "\n",
    "    # Create a tqdm progress bar for overall calculation\n",
    "    progress_bar = tqdm.tqdm(total=num_months, desc='Calculating Overall Percentage', unit='month', position=0)\n",
    "\n",
    "    # Loop through each month\n",
    "    for month in monthly_matrices:\n",
    "        # Extract relevant data for the month\n",
    "        monthly_matrix = monthly_matrices[month]\n",
    "\n",
    "        # Check if there are matrices available for this month\n",
    "        if len(monthly_matrix) > 0:\n",
    "            # Initialize overall sum and count arrays if not initialized\n",
    "            if overall_sum is None:\n",
    "                overall_sum = np.zeros_like(monthly_matrix[0])\n",
    "                overall_count = np.zeros_like(monthly_matrix[0])\n",
    "\n",
    "            # Update overall sum and count arrays with monthly data\n",
    "            overall_sum += np.sum(monthly_matrix == 1, axis=0)\n",
    "            overall_count += np.sum((monthly_matrix == 1) | (monthly_matrix == 0), axis=0)\n",
    "\n",
    "        # Increment the progress bar\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    if overall_sum is not None and overall_count is not None:\n",
    "        # Calculate the average monthly percentage\n",
    "        overall_percentage = (overall_sum / overall_count) * 100\n",
    "        return overall_percentage\n",
    "    else:\n",
    "        print(\"No data available for any month.\")\n",
    "        return None\n",
    "\n",
    "# Visualize overall water occurrence\n",
    "def visualize_overall_percentage(overall_percentage, output_folder, meshgrid_lon, meshgrid_lat):\n",
    "    height, width = meshgrid_lon.shape\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(overall_percentage, extent=(meshgrid_lon.min(), meshgrid_lon.max(), meshgrid_lat.min(), meshgrid_lat.max()), cmap='Blues', vmin=0, vmax=100)\n",
    "    plt.title(\"Overall Water Occurrence\")\n",
    "    plt.colorbar(label='Water Coverage Frequency')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5, color='black', alpha=0.5)\n",
    "\n",
    "    # Save the plot as PNG in the Output folder\n",
    "    output_path_png = output_folder / \"overall_water_occurrence.png\"\n",
    "    plt.savefig(output_path_png)\n",
    "    plt.close()\n",
    "    \n",
    "def check_and_move_images(modified_folder_path, output_folder):\n",
    "    cloud_threshold = float(input(\"Enter the cloud coverage threshold percentage (e.g., 10 for 10%): \")) / 100\n",
    "    num_images_processed = 0  # Initialize count of processed images\n",
    "    num_images_moved = 0  # Initialize count of moved images\n",
    "\n",
    "    # Create a folder to store rejected images\n",
    "    rejected_folder = output_folder / \"Rejected_Images\"\n",
    "    rejected_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # Loop through each modified image\n",
    "    for modified_image in modified_folder_path.iterdir():\n",
    "        num_images_processed += 1  # Increment count of processed images\n",
    "\n",
    "        # Open the modified image\n",
    "        modified_ds = gdal.Open(str(modified_image))\n",
    "        modified_array = modified_ds.ReadAsArray()\n",
    "\n",
    "        # Calculate the proportion of cloud pixels (value 4) in the image\n",
    "        cloud_pixels = np.sum(modified_array == 4)\n",
    "        total_pixels = modified_array.size\n",
    "        cloud_proportion = cloud_pixels / total_pixels\n",
    "\n",
    "        # Check if the proportion exceeds the threshold\n",
    "        if cloud_proportion >= cloud_threshold:\n",
    "            # Move the image to the rejected folder\n",
    "            new_path = rejected_folder / modified_image.name\n",
    "            modified_image.rename(new_path)\n",
    "            num_images_moved += 1  # Increment count of moved images\n",
    "    \n",
    "    #print(\"Image checking and moving process completed.\")\n",
    "    return num_images_processed, num_images_moved\n",
    "\n",
    "def evaluate_modified_images(modified_folder_path, monthly_percentages, meshgrid_lon, meshgrid_lat):\n",
    "    # Create a dictionary to store image dates\n",
    "    image_dates = {}\n",
    "\n",
    "    # Iterate through modified images and extract their dates\n",
    "    for modified_image in modified_folder_path.iterdir():\n",
    "        if modified_image.suffix.lower() in {\".tif\", \".tiff\"}:\n",
    "            # Extract date from filename\n",
    "            filename_parts = modified_image.stem.split('.')\n",
    "            julian_day = int(filename_parts[1][1:])\n",
    "            year = int(filename_parts[1][1:5])\n",
    "            date = datetime(year, 1, 1) + timedelta(days=julian_day - 1)\n",
    "            image_dates[modified_image.name] = date\n",
    "\n",
    "    # Create a list to store the modified image names\n",
    "    modified_images = list(image_dates.keys())\n",
    "\n",
    "    # Iterate through each modified image\n",
    "    for modified_image in modified_images:\n",
    "        # Get the date of the modified image\n",
    "        modified_date = image_dates[modified_image]\n",
    "\n",
    "        # Find nearby images for the modified image\n",
    "        nearby_images = []\n",
    "        for image_name, image_date in image_dates.items():\n",
    "            if abs(image_date - modified_date) <= timedelta(days=2) and image_name != modified_image:\n",
    "                nearby_images.append(image_name)\n",
    "\n",
    "        # If there are nearby images, compare cloud pixels using previous method\n",
    "        if nearby_images:\n",
    "            modified_ds = gdal.Open(str(modified_folder_path / modified_image), gdal.GA_Update)\n",
    "            modified_array = modified_ds.ReadAsArray()\n",
    "\n",
    "            for nearby_image in nearby_images:\n",
    "                nearby_ds = gdal.Open(str(modified_folder_path / nearby_image))\n",
    "                nearby_array = nearby_ds.ReadAsArray()\n",
    "\n",
    "                # Find cloud pixels in the modified image\n",
    "                cloud_pixels = np.where(modified_array == 4)\n",
    "\n",
    "                # Compare with corresponding pixels in the nearby image\n",
    "                for pixel in zip(*cloud_pixels):\n",
    "                    x, y = pixel\n",
    "                    if nearby_array[x, y] == 1:\n",
    "                        # Change cloud pixel to water in the modified image\n",
    "                        modified_array[x, y] = 1\n",
    "\n",
    "            # Write the modified array back to the modified image\n",
    "            modified_ds.GetRasterBand(1).WriteArray(modified_array)\n",
    "            modified_ds = None  # Close the dataset\n",
    "        else:\n",
    "            # If no nearby images, compare cloud pixels with related monthly water occurrence\n",
    "            month = modified_date.month\n",
    "            monthly_percentage = monthly_percentages[month - 1]\n",
    "\n",
    "            modified_ds = gdal.Open(str(modified_folder_path / modified_image), gdal.GA_Update)\n",
    "            modified_array = modified_ds.ReadAsArray()\n",
    "\n",
    "            # Find cloud pixels in the modified image\n",
    "            cloud_pixels = np.where(modified_array == 4)\n",
    "\n",
    "            # Compare with corresponding pixels in the related monthly water occurrence\n",
    "            for pixel in zip(*cloud_pixels):\n",
    "                x, y = pixel\n",
    "                if monthly_percentage[1][x, y] >= 90:  # Monthly percentage for water occurrence\n",
    "                    # Change cloud pixel to water in the modified image\n",
    "                    modified_array[x, y] = 1\n",
    "\n",
    "            # Write the modified array back to the modified image\n",
    "            modified_ds.GetRasterBand(1).WriteArray(modified_array)\n",
    "            modified_ds = None  # Close the dataset\n",
    "\n",
    "    #print(\"Image control process completed.\")\n",
    "\n",
    "def calculate_area(modified_folder_path):\n",
    "    water_area = []\n",
    "    cloud_area = []\n",
    "    dates = []\n",
    "\n",
    "    # Iterate through modified images\n",
    "    for modified_image in modified_folder_path.iterdir():\n",
    "        if modified_image.suffix.lower() in {\".tif\", \".tiff\"}:\n",
    "            # Extract date from filename\n",
    "            filename_parts = modified_image.stem.split('.')\n",
    "            year = int(filename_parts[1][1:5])\n",
    "            day_of_year = int(filename_parts[1][5:])\n",
    "            date = datetime(year, 1, 1) + timedelta(days=day_of_year - 1)\n",
    "            dates.append(date)\n",
    "\n",
    "            # Open modified image\n",
    "            modified_ds = gdal.Open(str(modified_image))\n",
    "            modified_array = modified_ds.ReadAsArray()\n",
    "\n",
    "            # Get pixel size from geotransform\n",
    "            geotransform = modified_ds.GetGeoTransform()\n",
    "            pixel_resolution_x = geotransform[1]\n",
    "            pixel_resolution_y = -geotransform[5]\n",
    "\n",
    "            # Calculate water area (count of water pixels)\n",
    "            water_pixels = np.sum(modified_array == 1)\n",
    "            # Calculate cloud area (count of cloud pixels)\n",
    "            cloud_pixels = np.sum(modified_array == 4)\n",
    "\n",
    "            # Assuming square pixels, multiply by pixel area to get water and cloud area in square meters\n",
    "            pixel_area_m2 = pixel_resolution_x * pixel_resolution_y  # Calculate pixel area in square meters\n",
    "            water_area_km2 = (water_pixels * pixel_area_m2) / 1e6  # Calculate water area in square kilometers\n",
    "            cloud_area_km2 = (cloud_pixels * pixel_area_m2) / 1e6  # Calculate cloud area in square kilometers\n",
    "\n",
    "            water_area.append(water_area_km2)\n",
    "            cloud_area.append(cloud_area_km2)\n",
    "\n",
    "            modified_ds = None  # Close the dataset\n",
    "\n",
    "    return dates, water_area, cloud_area\n",
    "\n",
    "def plot_area_time_series(dates, area, area_type, y_limits=None):\n",
    "    # Sort the dates and area values\n",
    "    sorted_indices = np.argsort(dates)\n",
    "    sorted_dates = [dates[i] for i in sorted_indices]\n",
    "    sorted_area = [area[i] for i in sorted_indices]\n",
    "\n",
    "    # Convert to pandas Series for rolling mean calculation\n",
    "    data_series = pd.Series(sorted_area, index=sorted_dates)\n",
    "    rolling_mean = data_series.rolling(window=5, min_periods=1).mean()  # Adjust window size as needed\n",
    "\n",
    "    # Calculate z-scores for blunder detection\n",
    "    z_scores = zscore(sorted_area)\n",
    "    blunders = np.where(np.abs(z_scores) > 3)[0]  # Identify blunders with z-scores greater than 3\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sorted_dates, sorted_area, marker='o', linestyle='-', label=area_type + \" Area\")\n",
    "    plt.plot(rolling_mean.index, rolling_mean.values, linestyle='--', color='red', label=\"Moving Average\")\n",
    "\n",
    "    # Highlight blunders\n",
    "    blunder_dates = [sorted_dates[blunder] for blunder in blunders]\n",
    "    blunder_values = [sorted_area[blunder] for blunder in blunders]\n",
    "    plt.scatter(blunder_dates, blunder_values, color='red', label='Blunders', zorder=5)\n",
    "\n",
    "    plt.title(area_type + \" Area Time Series\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(area_type + \" Area (kmÂ²)\")\n",
    "    if y_limits:\n",
    "        plt.ylim(y_limits)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def apply_maxflow_segmentation(image_path, overall_percentage, output_path, theta=0.5):\n",
    "    # Step 1: Load the TIFF image\n",
    "    dataset = gdal.Open(str(image_path))\n",
    "    if dataset is None:\n",
    "        print(f\"Error: Unable to open image {image_path}\")\n",
    "        return\n",
    "    \n",
    "    image = dataset.ReadAsArray()\n",
    "    unique_values = np.unique(image)\n",
    "    \n",
    "    # Check if the image has exactly three unique pixel values\n",
    "    if set(unique_values) != {0, 1, 4}:\n",
    "        #print(f\"Skipping {image_path.name}: Expected pixel values {0, 1, 4}, found {unique_values}.\")\n",
    "        return\n",
    "    \n",
    "    # Map pixel values to binary labels\n",
    "    value_to_label = {0: 0, 1: 1, 4: 2}\n",
    "    label_image = np.vectorize(value_to_label.get)(image)\n",
    "    \n",
    "    # Step 2: Set up the graph\n",
    "    height, width = image.shape\n",
    "    g = Graph[float](height * width, height * width * 4)\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    nodeids = g.add_grid_nodes((height, width))\n",
    "    \n",
    "    # Define neighborhood (4-connectivity)\n",
    "    structure = np.array([[0, 1, 0],\n",
    "                          [1, 0, 1],\n",
    "                          [0, 1, 0]], dtype=np.int8)\n",
    "    \n",
    "    # Define a small epsilon value to avoid log(0) or log(1)\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # Add edges based on overall_percentage\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            pixel_value = label_image[i, j]\n",
    "            prob = overall_percentage[i, j] / 100  # Convert percentage to probability\n",
    "            \n",
    "            # Ensure prob is within (epsilon, 1 - epsilon) to avoid log(0) and log(1)\n",
    "            prob = np.clip(prob, epsilon, 1 - epsilon)\n",
    "            \n",
    "            D_p_W = -np.log(prob)\n",
    "            D_p_L = -np.log(1 - prob)\n",
    "            \n",
    "            g.add_tedge(nodeids[i, j], D_p_W, D_p_L)\n",
    "\n",
    "    \n",
    "    # Add smoothness term\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if i + 1 < height:\n",
    "                V = 2 * theta if label_image[i, j] == label_image[i + 1, j] else 0\n",
    "                g.add_edge(nodeids[i, j], nodeids[i + 1, j], V, V)\n",
    "            if j + 1 < width:\n",
    "                V = 2 * theta if label_image[i, j] == label_image[i, j + 1] else 0\n",
    "                g.add_edge(nodeids[i, j], nodeids[i, j + 1], V, V)\n",
    "    \n",
    "    # Step 3: Compute the max-flow/min-cut\n",
    "    flow = g.maxflow()\n",
    "    #print(f\"Max flow value: {flow}\")\n",
    "    \n",
    "    # Get the segments\n",
    "    segments = g.get_grid_segments(nodeids)\n",
    "    \n",
    "    # Step 4: Generate the binary image\n",
    "    binary_image = np.int32(segments)\n",
    "    \n",
    "    # Save the binary image as a GeoTIFF\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    ds_out = driver.Create(str(output_path), width, height, 1, gdal.GDT_Byte)\n",
    "    ds_out.SetGeoTransform(dataset.GetGeoTransform())\n",
    "    ds_out.SetProjection(dataset.GetProjection())\n",
    "    ds_out.GetRasterBand(1).WriteArray(binary_image)\n",
    "    ds_out = None  # Close the dataset\n",
    "    \n",
    "    #print(f'Binary image saved to {output_path}')\n",
    "\n",
    "def calculate_binary_area(binary_folder_path):\n",
    "    water_area = []\n",
    "    dates = []\n",
    "\n",
    "    # Iterate through binary images\n",
    "    for binary_image in binary_folder_path.iterdir():\n",
    "        if binary_image.suffix.lower() in {\".tif\", \".tiff\"}:\n",
    "            \n",
    "            # Extract date from filename\n",
    "            filename_parts = binary_image.stem.split('.')\n",
    "            year = int(filename_parts[1][1:5])\n",
    "            day_of_year = int(filename_parts[1][5:])\n",
    "            date = datetime(year, 1, 1) + timedelta(days=day_of_year - 1)\n",
    "            dates.append(date)\n",
    "\n",
    "            # Open binary image\n",
    "            binary_ds = gdal.Open(str(binary_image))\n",
    "            binary_array = binary_ds.ReadAsArray()\n",
    "\n",
    "            # Get pixel size from geotransform\n",
    "            geotransform = binary_ds.GetGeoTransform()\n",
    "            pixel_resolution_x = geotransform[1]\n",
    "            pixel_resolution_y = -geotransform[5]\n",
    "\n",
    "            # Calculate water area (count of water pixels)\n",
    "            water_pixels = np.sum(binary_array == 1)\n",
    "\n",
    "            # Assuming square pixels, multiply by pixel area to get water area in square meters\n",
    "            pixel_area_m2 = pixel_resolution_x * pixel_resolution_y  # Calculate pixel area in square meters\n",
    "            water_area_km2 = (water_pixels * pixel_area_m2) / 1e6  # Calculate water area in square kilometers\n",
    "\n",
    "            water_area.append(water_area_km2)\n",
    "\n",
    "            binary_ds = None  # Close the dataset\n",
    "\n",
    "    return dates, water_area\n",
    "\n",
    "def main():\n",
    "    folder_path = get_valid_folder_path()\n",
    "\n",
    "    # Create the main output folder\n",
    "    output_folder = folder_path / \"Output\"\n",
    "    output_folder.mkdir(exist_ok=True)  # Create the Output folder if it doesn't exist\n",
    "\n",
    "    # Create subfolders within the Output folder\n",
    "    water_occurrence_folder = output_folder / \"Water_Occurrence\"\n",
    "    water_occurrence_folder.mkdir(exist_ok=True)\n",
    "    \n",
    "    modified_folder_path = output_folder / \"Modified_Images_WaterMask\"\n",
    "    modified_folder_path.mkdir(exist_ok=True)\n",
    "\n",
    "    rejected_folder = output_folder / \"Rejected_Images\"\n",
    "    rejected_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    binary_images_folder = output_folder / \"Binary_Images\"\n",
    "    binary_images_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    # Process images in the specified folder\n",
    "    monthly_matrices, meshgrid_lon, meshgrid_lat = process_image_folder(folder_path)\n",
    "\n",
    "    # Check if there are valid images\n",
    "    if monthly_matrices is not None:\n",
    "        # Calculate monthly percentages\n",
    "        monthly_percentages = calculate_monthly_percentage(monthly_matrices)\n",
    "\n",
    "        # Visualize monthly water occurrence percentages\n",
    "        visualize_monthly_percentage(monthly_percentages, water_occurrence_folder, meshgrid_lon, meshgrid_lat)\n",
    "\n",
    "        # Calculate overall percentage\n",
    "        overall_percentage = calculate_overall_percentage(monthly_matrices)\n",
    "\n",
    "        # Visualize overall water occurrence\n",
    "        visualize_overall_percentage(overall_percentage, water_occurrence_folder, meshgrid_lon, meshgrid_lat)\n",
    "\n",
    "        # Prompt the user for water percentage threshold\n",
    "        water_percentage_threshold = float(input(\"Enter the water mask percentage (e.g., 95): \"))\n",
    "\n",
    "        # Prompt the user for cloud mask threshold\n",
    "        cloud_mask_threshold = float(input(\"Enter the land mask percentage (e.g., 5): \"))\n",
    "\n",
    "        # Apply cloud masks and save modified images with water mask\n",
    "        image_files = [f for f in folder_path.iterdir() if f.suffix.lower() in {\".tif\", \".tiff\"}]\n",
    "        skipped_images = apply_cloud_masks(image_files, overall_percentage, water_percentage_threshold, cloud_mask_threshold, output_folder)\n",
    "\n",
    "        # Check and move images based on cloud proportion\n",
    "        num_images_processed, num_images_moved = check_and_move_images(modified_folder_path, output_folder)\n",
    "\n",
    "        # Calculate the percentage of images moved to rejected_images folder\n",
    "        if num_images_processed > 0:\n",
    "            percentage_moved = (num_images_moved / num_images_processed) * 100\n",
    "            print(f\"Percentage of images moved to rejected_images folder: {percentage_moved:.2f}%\")\n",
    "        else:\n",
    "            print(\"No images processed.\")\n",
    "\n",
    "        # Evaluate modified images based on nearby dates and compare cloud pixels\n",
    "        evaluate_modified_images(modified_folder_path, monthly_percentages, meshgrid_lon, meshgrid_lat)\n",
    "        \n",
    "        # Calculate water and cloud area time series\n",
    "        dates, water_area, cloud_area = calculate_area(modified_folder_path)\n",
    "\n",
    "        # Determine y-axis limits based on water area and cloud area\n",
    "        all_areas = water_area + cloud_area\n",
    "        y_limits = [min(all_areas) - 10, max(all_areas) + 10]\n",
    "\n",
    "        # Plot water area time series\n",
    "        plot_area_time_series(dates, water_area, \"Water\", y_limits=y_limits)\n",
    "\n",
    "        # Plot cloud area time series\n",
    "        plot_area_time_series(dates, cloud_area, \"Cloud\", y_limits=y_limits)\n",
    "\n",
    "        # Apply max-flow segmentation to modified images that were not skipped\n",
    "        modified_images = [f for f in modified_folder_path.iterdir() if f.suffix.lower() in {\".tif\", \".tiff\"} and f not in skipped_images]\n",
    "        for modified_image in tqdm.tqdm(modified_images, desc='Applying Max-Flow Segmentation', unit='image', position=0):\n",
    "            output_path = binary_images_folder / f\"segmented_{modified_image.name}\"\n",
    "            apply_maxflow_segmentation(modified_image, overall_percentage, output_path)\n",
    "\n",
    "        # Calculate water area time series for binary images\n",
    "        binary_dates, binary_water_area = calculate_binary_area(binary_images_folder)\n",
    "\n",
    "        # Plot water area time series for binary images\n",
    "        plot_area_time_series(binary_dates, binary_water_area, \"Binary Water\", y_limits=y_limits)\n",
    "                \n",
    "    print(\"\\nProcess finished.\")\n",
    "\n",
    "    # Generate JPG images from GeoTIFF files\n",
    "    create_jpg_images_from_geotiff(output_folder)\n",
    "\n",
    "def create_jpg_images_from_geotiff(output_folder):\n",
    "    parent_folder = output_folder\n",
    "    # Get a list of all subdirectories in the parent folder\n",
    "    subdirectories = [d for d in os.listdir(parent_folder) if os.path.isdir(os.path.join(parent_folder, d))]\n",
    "\n",
    "    # Define custom colors for each pixel value\n",
    "    colors = ['lightgreen', 'lightblue', 'white', 'white']\n",
    "\n",
    "    # Define corresponding labels for the legend\n",
    "    legend_labels = ['Field', 'Water', 'Cloud']  # Exclude Label 5\n",
    "\n",
    "    # Create a custom colormap\n",
    "    custom_cmap = ListedColormap(colors)\n",
    "\n",
    "    # Create legend handles, excluding Label 5\n",
    "    legend_handles = [Patch(color=color, label=label) for color, label in zip(colors[:4]+colors[5:], legend_labels)]\n",
    "\n",
    "    # Iterate through each subdirectory (each folder) in the parent folder\n",
    "    for subdirectory in subdirectories:\n",
    "        # Construct the path to the current subdirectory\n",
    "        subdirectory_path = os.path.join(parent_folder, subdirectory)\n",
    "\n",
    "        # Create a folder named \"jpg_folder\" if it doesn't exist\n",
    "        jpg_folder_path = os.path.join(subdirectory_path, 'jpg_images')\n",
    "        os.makedirs(jpg_folder_path, exist_ok=True)\n",
    "\n",
    "        # Get a list of all GeoTIFF files in the current subdirectory\n",
    "        tif_files = [f for f in os.listdir(subdirectory_path) if f.endswith('.tif')]\n",
    "\n",
    "        # Iterate through each GeoTIFF file in the current subdirectory\n",
    "        for tif_file in tif_files:\n",
    "            tif_file_path = os.path.join(subdirectory_path, tif_file)\n",
    "\n",
    "            # Extract lake name and date from the file name\n",
    "            match = re.match(r\".*?\\.A(\\d{4})(\\d{3})\\.(\\w+)\\..*\", tif_file)\n",
    "            if match:\n",
    "                year = match.group(1)\n",
    "                day_of_year = match.group(2)\n",
    "                lake_name = match.group(3)\n",
    "                \n",
    "                # Convert year and day of year to date format\n",
    "                date = datetime.strptime(year + day_of_year, \"%Y%j\")\n",
    "                formatted_date = date.strftime(\"%d.%m.%Y\")\n",
    "\n",
    "                # Open the GeoTIFF file\n",
    "                with rasterio.open(tif_file_path) as dataset:\n",
    "                    # Read raster band(s)\n",
    "                    band = dataset.read(1)\n",
    "\n",
    "                    # Extract geospatial information\n",
    "                    transform = dataset.transform\n",
    "                    height, width = band.shape\n",
    "                    extent = rasterio.transform.array_bounds(height, width, transform)\n",
    "\n",
    "                    # Convert longitude and latitude from meters to degrees\n",
    "                    lon_min, lat_min = extent[0], extent[1]\n",
    "                    lon_max, lat_max = extent[2], extent[3]\n",
    "                    lon_conversion_factor = 1 / 100000.0  # Convert from meters to degrees\n",
    "                    lat_conversion_factor = 1 / 100000.0  # Convert from meters to degrees\n",
    "                    lon_ticks = [lon_min, lon_max]\n",
    "                    lat_ticks = [lat_min, lat_max]\n",
    "                    lon_tick_labels = [f\"{tick * lon_conversion_factor:.1f}\" for tick in lon_ticks]\n",
    "                    lat_tick_labels = [f\"{tick * lat_conversion_factor:.1f}\" for tick in lat_ticks]\n",
    "\n",
    "                    # Display the image\n",
    "                    plt.imshow(band, cmap=custom_cmap, vmin=0, vmax=len(colors)-1, extent=[extent[0], extent[2], extent[1], extent[3]])\n",
    "\n",
    "                    # Add title with lake name and formatted date\n",
    "                    plt.title(f\"{lake_name} - {formatted_date}\")\n",
    "\n",
    "                    # Add axes labels with latitude and longitude\n",
    "                    plt.xlabel('Longitude (degrees)')\n",
    "                    plt.ylabel('Latitude (degrees)')\n",
    "\n",
    "                    # Set tick labels\n",
    "                    plt.xticks(lon_ticks, lon_tick_labels)\n",
    "                    plt.yticks(lat_ticks, lat_tick_labels)\n",
    "\n",
    "                    # Show grid lines\n",
    "                    plt.grid(True)\n",
    "\n",
    "                    # Add legend excluding Label 5\n",
    "                    plt.legend(handles=legend_handles, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "                    # Save the image as a JPG file in the \"jpg_folder\"\n",
    "                    jpg_file_path = os.path.join(jpg_folder_path, f\"{tif_file.replace('.tif', '_plot.jpg')}\")\n",
    "                    plt.savefig(jpg_file_path, bbox_inches='tight')\n",
    "\n",
    "                    # Close the plot to free up memory\n",
    "                    plt.close()\n",
    "\n",
    "                    # Show the saved image file path\n",
    "                    print(f\"Image saved: {jpg_file_path}\")\n",
    "\n",
    "# Execute the main function if the script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
